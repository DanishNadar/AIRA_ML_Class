# ML Class 01 - Linear Regression
### **Made and Presented by: Danish Nadar**

This repository contains materials and code from the **Illinois Tech Robotics Machine Learning Class 01**, where Danish Nadar presented foundational concepts of Machine Learning, specifically focusing on **Simple Linear Regression** and **Multiple Linear Regression**. The session included theory, coding demonstrations, and hands-on learning for students.

## **Goals of the Session**
1. Introduction to key terminology and concepts regarding AI/ML/DL/DS/DM/CV/NLP.  
2. Guided instruction to learn theory behind Simple and Multiple Linear Regression
3. Practical implementation of Machine Learning models.

---

## **Topics Covered**
### **1. What is Data Science (DS)?**
- An interdisciplinary field combining statistics, computer science, and programming.
- The Data Science Life Cycle involves data collection, processing, modeling, and evaluation.
- Data Science acts as an umbrella term for AI and its sibling, Data Mining (DM).

### **2. What is Artificial Intelligence (AI)?**
- Simulation of human intelligence by machines using large datasets and algorithms.
- AI subcategories include Machine Learning (ML), Deep Learning (DL), and more.

### **3. What is Deep Learning (DL)?**
- A subset of Machine Learning that uses neural networks to mimic the brainâ€™s way of learning.
- Capable of handling tasks such as Computer Vision (CV) and Natural Language Processing (NLP).

---

## **Plan for the Semester**
- Dive into the theory behind essential Machine Learning algorithms.
- Build at least one model during each session to apply theoretical knowledge practically.
- Work toward **Project AIRA** in subsequent sessions.
- Practical accomplishments can be highlighted on resumes and discussed during interviews.

---

## **Machine Learning Models Covered**
### **Simple Linear Regression**
- Involves one independent variable (x) and one dependent variable (y).
- A "line of best fit" models and predicts the output (y) for new input (x).
- The formula used: **y = mx + b**, with **h(\u0398)** often replacing **y** in research.
- Gradient Descent is used to minimize the loss function and optimize model parameters.
- **Visual Explanation:** Provided during the session.

### **Multiple Linear Regression**
- Involves multiple independent variables (x) predicting a single dependent variable (y).
- Extends Simple Linear Regression into multiple dimensions.
- Instead of finding a line, the algorithm finds a **plane of best fit**.
- **Visual Explanation:** Provided during the session.

---

## **Code Implementation**
### **Simple Linear Regression**
- Model to predict weights given height and heights given weight using a shared dataset.

### **Multiple Linear Regression**
- Model to predict house prices based on multiple attributes such as size, number of rooms, and location.

---

## **Teaching Contribution**
Danish Nadar:
- Created and presented the entire session.
- Coded the models and guided participants through the coding process.
- Taught attendees how to implement and understand regression models hands-on.

## **Associated Members/Learners**
- Pranav Bonagiri
- Otioh Konan
- Member 3
---


### **Why This README Was Created**
This README was created to summarize the materials and accomplishments of the Machine Learning Class 01 session conducted by Danish Nadar. The content structure was developed to highlight both theoretical and practical components, emphasizing the educational goas and coding implementations. By organizing information under meaningful headers, the README becomes accessible and informative for those who attended or want to learn about the session later.
